### Introduction

Advancements in artificial intelligence (AI) have opened up new approaches to address healthcare-related challenges. However, AI systems have not achieved their full practical applications, as they are developed with a predominant focus on technical aspects, neglecting considerations regarding their real-world integration and value. Additionally, applying machine learning to biased or poor-quality datasets can pose significant challenges, with ethical considerations play a critical role in technology-supported clinical decisions, yet these are often inadequately addressed in purely technical evaluations. Integrating AI systems into clinical settings may come with considerable costs and disruptions, necessitating a thorough justification for their deployment. As a result, the generalizability of AI systems and their successful adoption in healthcare may encounter obstacles. Consequently, a rigorous evaluation framework that assesses AI systems at different stages of their clinical deployment is essential. The growing potential of AI in healthcare necessitates a careful evaluation process that encompasses both technical and practical considerations at various stages of AI system deployment. Presently available frameworks tend to focus on specific aspects and might not be adequate for a comprehensive assessment. Developing a unified evaluation framework that addresses the functional, utility, and ethical dimensions of AI models is critical for fostering successful integration and adoption in healthcare settings.

Artificial Intelligence (AI) in the context of healthcare refers to the utilization of computational algorithms and machine learning methodologies to process extensive volumes of healthcare data and emulate human-like intelligence to execute diverse medical functions. AI systems in healthcare are designed to support healthcare professionals by facilitating precise diagnostics, generating tailored treatment strategies, streamlining medical workflows, and enhancing overall patient outcomes. Here we discuss how to evaluate AI readiness in the healthcare context and try to provide an overview of AI maturity models in healthcare. Evaluating AI readiness in the healthcare context requires careful consideration of several key factors. For instance, assessing the technical expertise of healthcare professionals and IT staff to determine their knowledge and skills in AI technologies and data analysis, evaluating the availability and quality of healthcare data, assessing the existing infrastructure and resources, including computing power and storage capacity, considering the regulatory and ethical frameworks surrounding AI in healthcare is important to ensure compliance with data privacy regulations and ethical guidelines. Moreover, evaluating the organizational culture and leadership support for AI adoption is essential to foster a willingness to embrace innovation and allocate resources, assessing the potential for collaboration and partnerships with AI technology providers and research institutions can facilitate knowledge sharing and accelerate AI implementation. These considerations collectively contribute to evaluating AI readiness in the healthcare context.

Here is some of these points with more details. 

+ **Technical Expertise**: Assessing the technical expertise of healthcare professionals and IT staff is essential. It involves evaluating their knowledge and skills in AI technologies, data analysis, and machine learning algorithms.

+ **Data Availability and Quality**: Evaluating the availability and quality of healthcare data is crucial for AI readiness. This includes assessing the accessibility of electronic health records, medical imaging data, and other relevant datasets necessary for training and testing AI models.

+ **Infrastructure and Resources**: Assessing the existing infrastructure and resources is important to determine if they can support AI implementation. This includes evaluating the computing power, storage capacity, and network capabilities required for AI algorithms to run efficiently.

+ **Regulatory and Ethical Considerations**: Evaluating the regulatory and ethical frameworks surrounding AI in healthcare is crucial. It involves assessing compliance with data privacy regulations, patient consent, and ethical guidelines for AI implementation.

+ **Organizational Culture and Leadership**: Assessing the organizational culture and leadership support for AI adoption is essential. It involves evaluating the willingness to embrace change, promote innovation, and allocate resources for AI initiatives.

+ **Collaboration and Partnerships**: Evaluating the potential for collaboration and partnerships with AI technology providers, research institutions, and other healthcare organizations is important. It can facilitate knowledge sharing, access to expertise, and accelerate AI implementation.

+ **Data Governance and Management**: Developing a robust data governance and management strategy is crucial for AI readiness. It involves establishing policies and procedures for data collection, storage, sharing, and analysis to ensure data quality, security, and privacy.

+ **Performance Metrics and Evaluation**: Developing performance metrics and evaluation criteria is essential to monitor and evaluate the effectiveness of AI implementation. It involves establishing key performance indicators (KPIs) and metrics to measure the impact of AI on patient outcomes, clinical workflows, and organizational efficiency.

+ **Training and Education**: Providing training and education to healthcare professionals and IT staff is crucial for AI readiness. It involves developing training programs to enhance technical expertise, data analysis skills, and knowledge of AI technologies and their applications in healthcare.

By considering these key components, healthcare organizations can develop a comprehensive AI readiness framework that addresses the technical, regulatory, ethical, organizational, and cultural aspects of AI implementation. An effective AI readiness framework can help organizations harness the potential of AI to improve patient care and outcomes.




### Best practices
Implementing AI in healthcare requires careful consideration and adherence to best practices. Here are some key best practices for healthcare providers to implement AI in their practice:

1. **Define Clear Objectives**: Clearly define the objectives and goals of implementing AI in healthcare. Identify specific areas where AI can be applied to improve patient care, diagnosis, treatment, or operational efficiency.

2. **Data Quality and Accessibility**: Ensure that the data used for AI algorithms is of high quality, accurate, and accessible. Establish data governance policies and procedures to maintain data integrity, privacy, and security.

3. **Collaboration and Interdisciplinary Teams**: Foster collaboration between healthcare professionals, data scientists, AI experts, and IT professionals. Create interdisciplinary teams to work together on AI projects, combining clinical expertise with technical knowledge.

4. **Ethical Considerations**: Address ethical considerations related to AI implementation in healthcare. Ensure compliance with privacy regulations, informed consent, and transparency in AI algorithms. Develop guidelines and protocols for responsible AI use.

5. **Continual Monitoring and Updating**: Continually monitor and update AI algorithms to ensure their performance and accuracy. Establish processes for monitoring algorithmic performance and updating models based on new data or emerging evidence[1].

6. **Training and Education**: Provide training and education to healthcare professionals on AI concepts, applications, and limitations. Offer opportunities for healthcare providers to enhance their knowledge and skills in AI through workshops, courses, and online resources[3].

7. **Start with Pilot Projects**: Begin with small-scale pilot projects to test and validate AI solutions before full-scale implementation. This allows for iterative improvements and adjustments based on real-world feedback and outcomes.

8. **Evaluate Impact and Outcomes**: Regularly evaluate the impact and outcomes of AI implementation in healthcare. Measure the effectiveness of AI in improving patient outcomes, clinical workflows, and operational efficiency. Use performance metrics and evaluation criteria to assess the success of AI initiatives.

9. **Stay Updated on Advances**: Stay informed about the latest advancements and research in AI technologies and their applications in healthcare. Attend conferences, join professional associations, and engage in knowledge-sharing platforms to stay up-to-date with the evolving field of AI in healthcare[2].

10. **Address Barriers and Challenges**: Recognize and address the barriers and challenges associated with AI implementation in healthcare. These may include technical limitations, data privacy concerns, resistance to change, and regulatory complexities. Develop strategies to overcome these barriers and ensure smooth implementation.

By following these best practices, healthcare providers can effectively implement AI technologies in their practice, leading to improved patient care, enhanced clinical decision-making, and increased operational efficiency.

### How to enhance understanding of AI in healthcare

Understanding AI in healthcare empowers healthcare professionals to use it for better patient care, resource management, smart decisions, ethical practices, research advancements, and teamwork. By staying informed and using AI responsibly, healthcare pros can bring positive changes to healthcare and improve patient health. Healthcare providers can enhance their understanding and proficiency through participation in continuing education programs focused on AI in healthcare can provide healthcare providers with valuable knowledge and skills. These programs may include workshops, seminars, webinars, and online courses specifically designed to educate healthcare professionals about AI technologies and their applications in healthcare. Another aspect to take into consideration is collaboration with AI experts, such as data scientists, machine learning engineers, and AI researchers to help healthcare providers gain insights into AI methodologies and best practices. Establishing partnerships with academic institutions, research organizations, or AI technology companies can facilitate knowledge sharing and access to expertise. Engaging in collaborative projects and research initiatives that involve AI can provide healthcare providers with hands-on experience and practical knowledge. By actively participating in AI projects, healthcare providers can gain insights into data analysis, AI model development, and the implementation of AI solutions in healthcare settings. Internal Training Programs: Healthcare organizations can develop internal training programs to educate their staff about AI technologies and their applications in healthcare. These programs can include workshops, seminars, or online modules tailored to the specific needs of healthcare providers. Internal training programs can help healthcare providers understand how AI can be integrated into their clinical workflows and enhance patient care. Along these lines healthcare organizations can identify and designate internal AI champions who can serve as mentors and guides for other healthcare providers. These AI champions can share their knowledge and experiences, provide training sessions, and offer support to colleagues interested in learning about AI. By actively pursuing these strategies, healthcare providers can enhance their knowledge and skills in AI, enabling them to effectively leverage AI technologies to improve patient care, diagnosis, treatment, and overall healthcare outcomes.


### AI Maturity Models

AI maturity models (AIMMs) play a crucial role in assessing an organization's readiness and progress in adopting artificial intelligence (AI) technologies. However, the definitions and components of AIMMs vary across studies, indicating a lack of consensus in the field. The chosen studies highlight different characteristics and components of AIMMs. The studies reveal variations in the number of levels, descriptors, and elements used in AIMMs. Some studies lack clarity in how dimensions are evaluated, while others focus on specific industries or domains. The different designations used for elements indicate a lack of standard terminology in the field. However, dimensions are often considered the core of AIMMs, representing the maturity levels.  While there is no unified definition or standard components, AIMMs provide insights into an organization's progress in adopting AI technologies. Future research should aim to establish a common understanding and standardize the terminology and components of AIMMs to facilitate better evaluation and comparison across organizations.For instance, the Gartner AI Maturity Model outlines five levels of maturity: Foundation, Opportunistic, Methodical, Strategic, and Transformed. At the Foundation level, organizations establish basic data management practices. The Opportunistic level involves piloting AI projects in specific domains. In the Methodical level, organizations develop standardized processes for AI implementation. The Strategic level focuses on enterprise-wide integration and AI-driven decision-making. Finally, the Transformed level represents organizations that have fully embraced AI and achieved significant outcomes.


#### Overview of AI Maturity Models in Healthcare

A maturity model (MM) describes the growth and development of capability maturity over time in discrete but coordinated stages which describe the organizational behaviors, practices, and processes that reliably and sustainably produce the required outcomes. Monitoring and evaluation of organizational behaviors, operating procedures, and policies along the maturity stages is quality measurement and improvement. Likewise,valuating AI readiness is a critical step in successfully integrating AI technologies in healthcare. The use of AI maturity models provides a structured approach to assess an organization's current state, identify gaps, and plan for AI implementation. By considering technological infrastructure, data availability, workforce skills, regulatory compliance, and organizational culture, healthcare institutions can better navigate the complex landscape of AI adoption. Such evaluation enables informed decision-making, enhances patient care, and maximizes the potential benefits of AI in healthcare.

##### HIMSS Analytics AI Maturity Model

The model is developed by HIMSS (Healthcare Information and Management Systems Society), a global organization focused on advancing healthcare through the best use of information technology. The HIMSS Analytics AI Maturity Model consists of different stages or levels, each representing increasing degrees of AI adoption and sophistication. The HIMSS Analytics AI Maturity Model offers a six-stage framework: Ad Hoc, Awareness, Exploration, Preparatory, Operational, and Transformational. The Ad Hoc stage represents limited AI adoption, while the Awareness stage involves understanding AI concepts and potential benefits. The Exploration stage focuses on identifying AI use cases and building internal expertise. In the Preparatory stage, organizations develop strategies and infrastructure for AI implementation. The Operational stage signifies active use of AI solutions, and the Transformational stage represents a fully integrated and optimized AI ecosystem.


##### Digital Health Profile and Maturity Assessment Toolkit (DHPMAT)

The Digital Health Profile and Maturity Assessment Toolkit (DHPMAT) describes 

Five essential DH foundations: 


+ Information communication **technology infrastructure**, access, and equity
  + This involves the evaluation of 21 indicators to determine the overall development of Information and Communication Technology (ICT). The assessment focuses on aspects such as ICT coverage, access, affordability, and resilience. The aim is to understand the distribution and reach of the national digital health program.

+ Essential **DH tools**
  + The evaluation of 39 indicators is used to assess the current implementation and utilization of crucial digital health tools. These tools include unique identifiers, health information systems like Electronic Medical Records (EMR) or Electronic Health Records (EHR), clinical decision support, telemedicine, mHealth, social media, eLearning, and big data analytics. The focus is on the development and maintenance of the national health data asset, which includes registers and EMRs/EHRs.
    
+ Readiness to **share information**
  + Assessment of 27 indicators to evaluate the readiness in terms of interoperability framework, architecture, standards, data quality, and legal frameworks. This evaluation aims to understand how health and other information are collected and managed to meet a standard.

+ Enablers of **trust and adoption**
  + This involves the evaluation of 31 indicators, including leadership, governance, funding, current strategy, and investment in digital health, as well as digital and health literacy. The assessment also looks into capacity building for digital health development and deployment, as well as the availability of digital health services and applications. The focus is on understanding the deployment of digital health literacy projects and assessing the complexity of digital health interventions and projects.

+ Quality improvement,monitoring, and evaluation (**QIME**)
  + This section describes various QIMME programs, ranging from single-site, ad hoc evaluations to multi-site implementations with comparative effectiveness research. The aim is to evaluate large-scale implementations with an assessment of financial and economic value and measurements of impacts on processes and outcomes. Indicators are used to assess and monitor the improved sharing of interoperable and fit-for-purpose data (data quality), quality of care, equity, and access to care. Additionally, the RE-AIM elements of implementation, including Reach, Effectiveness, Adoption, Implementation, and Maintenance at individual, community, and organizational levels, are also monitored and assessed.


Five stages of maturity: 

+ Basic
+ Controlled
+ Standardized
+ Optimized
+ Innovating


##### Translational Evaluation of Healthcare AI (TEHAI) 

The Translational Evaluation of Healthcare AI (TEHAI) framework has been guided by specific principles in its development. The essential components were considered in the framework and formulated an initial draft version of TEHAI. TEHAI framework offers a comprehensive approach to evaluating healthcare AI, covering aspects ranging from **technical competence to usability and practical integration**. By employing this framework, stakeholders can gain valuable insights into the effectiveness and applicability of AI systems, thus enhancing their potential impact on healthcare practices.

One of the key components of TEHAI is **Capability**, which examines the intrinsic technical competence of the AI system in fulfilling its intended purpose. This evaluation involves a thorough assessment of how the AI system was developed, including proper training and testing protocols, as these are pivotal to ensuring the system's effectiveness in healthcare settings. 

+ Capability Assessment:

The Capability component evaluates the intrinsic technical competence of the AI system to fulfill its intended purpose. Key aspects of the AI system's development process are scrutinized. Adequate training and testing of the model are crucial for the system's usefulness in healthcare environments.

  + Objective Assessment:

This subcomponent focuses on the ethical justification of the system's objective. The study's stated contribution to addressing a specific healthcare problem, aiming to reduce morbidity and/or mortality and enhance efficiency, is assessed. The clarity with which the objective is articulated, including the problem the AI addresses, the study's purpose, and its contribution to the domain's knowledge, determines the scoring.

  + Dataset Source and Integrity Evaluation:

The quality of an AI system is contingent on the data it is derived from. This subcomponent assesses the data source and integrity of datasets used to train and test the AI system. The representation and coverage of the target population in the data, along with the data collection process's consistency and reproducibility, are appraised. The scoring considers how well the dataset is described, its alignment with the objective from a technical standpoint, and the credibility and reliability of the data source.

  + Internal Validity Analysis:

An internally valid model demonstrates reliable and accurate predictions of health outcomes using the training data. The validation process includes measures of goodness-of-fit and cross-validation schemes that use data from the same sources for training and testing. Scoring accounts for the size and properties of the training data set relevant to the healthcare challenge, data diversity to ensure comprehensive modeling coverage, and statistical performance meeting the requirements for usefulness in healthcare.

  + External Validity Assessment:

External validity evaluation examines whether external data used to assess model performance originate from sources independent of the model construction team or were collected at substantially different times. The scoring considers the size and coverage of external data and the variation present to allow meaningful statistical conclusions.

  + Performance Metrics Examination:

Performance metrics are mathematical formulas used to assess how well an AI model predicts clinical or health outcomes. Proper selection of metrics is essential for reliable accuracy assessment. Biases inherent in specific metrics warrant consideration, and using multiple metrics may provide more reliable conclusions. This subcomponent evaluates whether appropriate performance measures were selected for study presentation, taking into account the healthcare challenge's nature and considering the reliability of the metrics across domains or during model updates.

  + Use Case Justification:

This subcomponent investigates the rationale for utilizing AI in the study, distinct from evaluating statistical or analytical methods. It examines whether the study provides evidence or arguments justifying the AI method's relevance and fit for the specific healthcare domain it is applied to. The scoring considers how well the use case is articulated and whether the study presents evidence or arguments justifying the AI method's application.

The **Utility** component of TEHAI focuses on the usability of the AI system, encompassing various dimensions such as contextual relevance, safety, and ethical considerations during potential clinical deployment. Additionally, this component evaluates the system's efficiency in achieving maximum productivity while maintaining competency, gauged through quality, adoption, and alignment measures. By assessing these dimensions, Utility helps determine the applicability of the AI system for specific use cases and the broader domain.

Another critical aspect of TEHAI is the **Adoption** component, which addresses the challenges associated with integrating AI systems into healthcare delivery, despite their demonstrated efficacy in in-silico or controlled environments. Evaluating the translational value of current AI systems, this component assesses key elements that demonstrate the practical adoption of the model in real-life settings.


##### AI Readiness Index for Hospitals (AI-RIH) 

The development of an AI Readiness Index for Hospitals (AI-RIH) is proposed as a means to enhance organizational readiness and address potential barriers that could impede the effective implementation of AI in healthcare settings. AI readiness, in this context, refers to an organization's preparedness to adopt AI-related applications and technology-driven changes. For healthcare institutions, AI readiness is defined as the capacity to overcome healthcare-specific obstacles and fully capitalize on the innovative potential of AI. While a specific index is not presented, six fundamental categories that an index should encompass are outlined: 

+ Electronic health records, data quality, and interoperability
+ Data security, privacy, and regulatory compliance
+ Patient consultation and safety
+ AI upskilling, leadership, and change potential
+ AI innovation and research
+ AI partnerships and procurement.

Going beyond digital indices for hospitals, a comprehensive policy approach to AI readiness benchmarking is suggested to identify transformation gaps and harness AI's potential in healthcare. The AI-RIH is motivated by the mixed success of previous AI projects, the necessity for long-term preparation, and the widening gap between hospitals' health information technology status and the private sector. Failure to adequately prepare for AI could lead to technology projects that disrupt hospital care or erode trust among staff and patients. While the concept of an AI-RIH for hospitals is promising, its design and composition raise questions. The index development process entails various steps, such as theoretical framework development, data selection, normalization, and stakeholder consultation, and requires continuous usability testing. Instead of delving into the technical aspects of index development, the focus shifts to discussing the desired properties of an AI-RIH, potential limitations, and ideas for its implementation and utilization for benchmarking hospitals' AI readiness. Research and specialty hospitals often possess more independent oversight and receptive cultures, making them better suited for higher degrees of digitization and workforce upskilling. These hospitals can serve as pioneers or hubs driving AI adoption and innovation. In contrast, smaller district hospitals may rely on regional AI strategies due to limited financial and human resources. Furthermore, technology adoption is particularly complex in hospitals with a high degree of specialization, making specialty and research hospitals more likely to embrace their role as innovators and examples for challenging technology implementation scenarios, including education, spin-outs, and partnerships.

##### Van de Sande D, Van Genderen

The authors present a methodical and systematic approach to facilitate the development of Artificial Intelligence and ensure its safe integration into clinical practice. The implementation of this approach requires collaboration among interdisciplinary research teams, who should diligently adhere to relevant regulations. Furthermore, transparent publication of their research findings is crucial, and the utilization of referenced guidelines and good practices can provide valuable support in this endeavor.

+ Phase 0: Preparations Prior to AI Model Development
The initial phase involves defining the clinical problem that the AI model aims to address and engaging relevant stakeholders. The AI models should be designed to enhance patient care and tackle clinically significant issues. To ensure their efficacy, these models should produce actionable outputs linked to clinical decision-making. Before commencing the development of the AI model, it is crucial to establish the clinical problem and its significance.

+ Phase I: AI Model Development
In this phase, the data extracted directly from hospital information systems undergo preparation and preprocessing. Raw data, especially monitoring data, may contain errors that could introduce bias into the AI model. Hence, data preparation and preprocessing are necessary to mitigate such issues. Different AI models, such as traditional statistical models like logistic regression or advanced AI models like neural networks, can be employed to address the clinical problem effectively.

+ Phase II: Assessment of AI Performance and Reliability
Once the AI model is developed locally, it is imperative to evaluate its performance and reliability through external validation. AI models, unlike traditional medical devices, provide patient-specific predictions, making their generalizability and safety essential considerations. External validation helps determine the model's suitability and applicability across various settings. While broad generalizability might be challenging, site-specific training can enhance the model's performance within specific practice settings.

+ Phase III: Clinically Testing AI
Clinical AI studies should ideally be conducted in a randomized setting, with detailed steps to facilitate replication by others. These studies may adopt different designs, similar to traditional medical research, necessitating considerations such as randomization, multicentricity, and blinding. Adherence to the Standard Protocol Items: Recommendations for Interventional Trials–Artificial Intelligence guideline is crucial throughout this phase.

+ Phase IV: Implementing and Governing AI
After successful validation, the AI model can be implemented clinically. This phase involves obtaining legal approval, addressing regulatory aspects, and establishing data and model governance. A dedicated quality management system should be in place to monitor the AI model's performance continuously. Prompt identification of any deteriorating model performance allows timely actions such as retiring, retraining, adjusting, or switching to alternative models. Governance over data and AI model management is of utmost importance, covering aspects like data security, data quality, access, and overall accountability, in accordance with guidelines like FAIR (Findable, Accessible, Interoperable, and Reusable).


#### Vision in Quebec: OBVIA

OBVIA recenctly pulished a fact sheet that presents the main promises (or potential benefits or use cases) of AI in healthcare from the point of view of universal healthcare, the one that aims to improve the health of the population as well as the experience of patients and caregivers. These potential benefits are presented for the most promising uses of artificial intelligence systems (AIS), with a focus on recent developments in AI techniques (e.g. machine learning). This fact sheet does not cover the full potential of AIS to improve health, particularly in support of research, discovery and public health (e.g. prevention and protection). Before presenting the various promises, it is important to emphasize that AIS are not inter- ventions that are easy to circumscribe and evaluate. 

In other words, defining the effectiveness of an AIS is a complicated process, due to the very nature of this type of technology. Firstly, it is sometimes difficult to establish whether a digital tool includes an AIS. The term "AI-mobilized tools" will be used to refer to digital tools that might include one or more AIS. Secondly, the development of AIS based on recent machine learning techniques is special in that it requires so-called real-life data (or routine data, i.e. taken from the daily activities of clinicians or patients) in order to learn. These data are therefore necessarily local, and difficult to transpose from one context to another. This means that we need to put in place safeguards to ensure that an AIS that has been developed in another context still performs as well when implemented locally. It should be noted, however, that the technical performance of an AIS should not be confused with the effectiveness of an AI-enabled tool, once deployed and used on a daily basis. In fact, digital tools can be used in a multitude of ways by targeted users, and can be integrated differently into the way they work. This means that the sequence between the deployment of a digital tool mobilizing AI in a given context, and the benefits (all the advantages linked to this use of the tool, whether direct or indirect) that could be linked to it, is far from easy to trace. It is therefore important to clearly define how to judge the quality of a tool mobilizing AI in healthcare, firstly in its technical components (AIS performance), but also in its uses (used by whom, when, how?). For example, a tool that is deployed but not used to its full potential, by all its intended users (e.g., all clinicians, all patients, etc.), will find it difficult to realize the promised benefits.

The promises of tools mobilizing AI in healthcare must therefore be approached with caution. They rely both on a quality tool (which has the potential to deliver on the promises), which is also aligned with the local context (which can fit into practices, be adopted and used routinely, to enable the promises to be realized). This is why attention must be focused not only on the tool itself, but also on the behaviors (usage practices) associated with it. Finally, it's also important to remember that the development and use of AI-enabled tools can generate negative or harmful consequences, as well as risks for direct users, or more generally for an organization or society as a whole. 

Overall, the most mature tools are those associated with sensor-based data (e.g. radiography, photography). However, several parameters still limit the performance of these tools, as inputs are influenced by the characteristics of the device used to capture the image and/or signal, as well as practices leading to image annotation (which establishes the ground truth or gold standard) for model training and validation. Other types of data (e.g. clinical signs, symptoms, laboratory data, socio-demographics) are more difficult to use to train an AI model, since they are more heterogeneous and less standardized. Similarly, clinical documentation practices (e.g. coding, free-text clinical notes) will influence the type and quality of data available in a computerized clinical record. These factors must be taken into account in the local validation of an AIS that has been developed with data from another environment. This is why, when evaluating an AIS, it is important to focus not only on performance at the design stage, but also on performance during deployment, where practices, devices and related information systems may differ. This requires a high degree of transparency, which is far from the norm, even in the scientific literature.

Digital tools for use cases requiring heterogeneous clinical data as input are therefore less mature. To ensure that AIS mobilizing heterogeneous clinical data as input are effective and safe (and therefore unbiased), it is important to pay particular attention to the nature and types of input, including local information system data models, local data coding standards, as well as local data capture and quality analysis practices prior to their use for secondary use (develop an AI model). For example, complicated clinical conditions, with a diversity of symptoms or high variability of manifestations between individuals, become difficult to represent numerically in a uniform and unambiguous way.

### References

+ https://www.ncbi.nlm.nih.gov/pmc/articles/PMC9746075/
+ https://pubmed.ncbi.nlm.nih.gov/33258359/
+ https://bmcmededuc.biomedcentral.com/articles/10.1186/s12909-021-02546-6
+ https://www.cambridge.org/core/books/abs/ai-in-ehealth/organisational-readiness-for-the-adoption-of-artificial-intelligence-in-hospitals/4297BBCEC08130B0C1540127EE8D63C1
+ https://www.nature.com/articles/s41746-022-00611-y
+ https://bmcmedicine.biomedcentral.com/articles/10.1186/s12916-019-1426-2
+ https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8654471/
+ https://www.mdpi.com/2071-1050/14/18/11698
+ https://pubmed.ncbi.nlm.nih.gov/33258359/
+ https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6616181/
