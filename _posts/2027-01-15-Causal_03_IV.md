

### Healthcare Example: Estimating the Causal Effect of Hospital Quality on Patient Recovery

#### Context and Problem
Suppose we want to estimate the causal effect of hospital quality (treatment) on patient recovery time after surgery (outcome). For simplicity, let’s define hospital quality as a binary variable \( D_i \in \{0, 1\} \), where \( D_i = 1 \) indicates a patient is treated at a high-quality hospital (e.g., one with advanced facilities and experienced staff) and \( D_i = 0 \) indicates a standard hospital. The outcome \( Y_i \) is the number of days until recovery, and lower values indicate faster recovery. A naive approach might compare recovery times between patients at high-quality versus standard hospitals using regression:

\[
Y_i = \beta_0 + \beta_1 D_i + \beta_2 X_i + \epsilon_i
\]

where \( X_i \) includes observed confounders like age, sex, and pre-existing conditions. However, unmeasured confounding—such as patients’ socioeconomic status or health consciousness—may bias \( \beta_1 \). For example, wealthier or more health-conscious patients might choose high-quality hospitals *and* recover faster due to better overall health, not hospital quality.

#### Instrumental Variables Approach
To address this, we use IV estimation, leveraging an instrument \( Z_i \) that influences hospital choice but not recovery time except through hospital quality. A plausible instrument is **geographic proximity to a high-quality hospital**, defined as a binary variable \( Z_i = 1 \) if the patient lives within 10 miles of a high-quality hospital and \( Z_i = 0 \) otherwise. The intuition is that patients closer to a high-quality hospital are more likely to choose it due to convenience, but proximity itself does not directly affect recovery time (except through hospital choice).

The IV framework requires three assumptions, as outlined in your prior query:

1. **Relevance**: Proximity must influence hospital choice:

\[
\text{Cov}(Z_i, D_i) \neq 0
\]

Patients living closer to a high-quality hospital are more likely to attend it, perhaps due to lower travel costs or familiarity. This can be tested empirically by checking if \( Z_i \) predicts \( D_i \) in a first-stage regression.

2. **Exclusion Restriction**: Proximity affects recovery time \( Y_i \) only through hospital choice \( D_i \), not directly or via other channels. For instance, living near a high-quality hospital shouldn’t influence recovery through factors like local healthcare access, assuming similar baseline care quality across regions.

3. **Independence**: Proximity is “as good as randomly assigned,” independent of potential outcomes \( Y_i(1), Y_i(0) \):

\[
Z_i \perp \{Y_i(1), Y_i(0)\}
\]

This assumes proximity is not correlated with unmeasured confounders like patient health consciousness, which holds if residential patterns are unrelated to health behaviors after controlling for observed covariates \( X_i \).

Under these assumptions, IV estimates the **Local Average Treatment Effect (LATE)**, the causal effect of high-quality hospital care on recovery time for **compliers**—patients who choose a high-quality hospital because they live nearby but would choose a standard hospital if they lived farther away.

#### Formal Estimation
The IV effect can be estimated using the **Wald estimator** for binary \( Z_i \) and \( D_i \):

\[
\widehat{\text{LATE}} = \frac{\mathbb{E}[Y_i \mid Z_i = 1] - \mathbb{E}[Y_i \mid Z_i = 0]}{\mathbb{E}[D_i \mid Z_i = 1] - \mathbb{E}[D_i \mid Z_i = 0]}
\]

The numerator is the difference in average recovery times between patients living near versus far from a high-quality hospital (the reduced-form effect). The denominator is the difference in the probability of attending a high-quality hospital based on proximity (the first-stage effect). For example, if patients near a high-quality hospital recover 2 days faster on average, and proximity increases the likelihood of attending a high-quality hospital by 0.4, the LATE is \(-2 / 0.4 = -5\) days, meaning high-quality hospitals reduce recovery time by 5 days for compliers.

Alternatively, we can use **two-stage least squares (2SLS)** for more flexibility, especially with continuous outcomes or covariates:

1. **First Stage**: Regress hospital quality \( D_i \) on proximity \( Z_i \) and covariates \( X_i \):

\[
D_i = \pi_0 + \pi_1 Z_i + \pi_2 X_i + \nu_i
\]

2. **Second Stage**: Regress recovery time \( Y_i \) on the predicted hospital quality \( \hat{D}_i \) and covariates:

\[
Y_i = \alpha_0 + \alpha_1 \hat{D}_i + \alpha_2 X_i + \varepsilon_i
\]

The coefficient \( \alpha_1 \) estimates the LATE, adjusted for covariates like age or comorbidities to improve precision.

#### Interpretation
Suppose the IV estimate suggests that high-quality hospitals reduce recovery time by 5 days for compliers. This effect applies to patients whose hospital choice is swayed by proximity, not necessarily all patients. For instance, patients who always seek high-quality hospitals (regardless of distance) or those who never do are excluded from this estimate. This specificity is a key feature of IV, distinguishing it from methods targeting broader effects.

#### Practical Considerations
The validity of the IV approach hinges on the instrument’s assumptions. Relevance can be checked by ensuring a strong first-stage relationship (e.g., an F-statistic > 10 for \( \pi_1 \)). The exclusion restriction is harder to verify; we must argue that proximity doesn’t affect recovery through other channels, like local healthcare infrastructure. Independence requires that proximity isn’t correlated with unmeasured factors like wealth, which might be plausible after controlling for observables like income or education. Sensitivity analyses or falsification tests (e.g., checking if proximity affects outcomes in a non-surgical context) can bolster confidence. Weak instruments, where proximity only marginally affects hospital choice, could lead to imprecise estimates, necessitating robust methods like limited-information maximum likelihood.

#### Comparison with DML and DiD
Referring to the updated **Summary Table: Techniques for Causal Statistical Analysis**, IV differs from Double Machine Learning (DML) and Difference-in-Differences (DiD) in key ways. DML, as described in your prior query, assumes conditional ignorability (\( \{Y_i(1), Y_i(0)\} \perp D_i \mid X_i \)) and uses machine learning to model nuisance functions (outcome and propensity score) in high-dimensional settings. In the hospital quality example, DML would require all confounders (e.g., health consciousness) to be observed and included in \( X_i \), estimating the ATE for all patients. IV, by contrast, handles unmeasured confounding via the instrument (proximity) but estimates the LATE for compliers, requiring no assumption about observed confounders but a valid instrument. DML is more robust to model misspecification but fails if key confounders are unmeasured, unlike IV.

DiD, which relies on parallel trends (\( \mathbb{E}[Y_{i1}(0) - Y_{i0}(0) \mid D_i = 1] = \mathbb{E}[Y_{i1}(0) - Y_{i0}(0) \mid D_i = 0] \)), is suited for settings with pre- and post-treatment data. If we were studying a policy improving hospital quality in certain regions, DiD could compare recovery time changes between treated and control regions. However, DiD assumes no differential trends in unmeasured confounders, which may not hold if high-quality hospitals attract healthier patients over time. IV avoids this by using proximity as an exogenous shock, but it requires a valid instrument, which DiD does not.

#### Conclusion
This IV example—using proximity to estimate the effect of hospital quality on recovery time—illustrates how IV addresses unmeasured confounding in healthcare. By leveraging an external source of variation, IV provides a causal estimate for compliers, offering a robust alternative when randomization is infeasible. Compared to DML, IV relaxes the need for all confounders to be observed but demands a valid instrument. Compared to DiD, IV doesn’t rely on temporal data or parallel trends, making it suitable for cross-sectional studies. The approach’s strength lies in its ability to handle endogeneity, but its reliance on strong assumptions about the instrument underscores the need for careful justification and robustness checks. If you’d like a deeper exploration (e.g., testing assumptions or extending to heterogeneous effects), let me know!


Below, I provide R code to implement the Instrumental Variables (IV) approach for the healthcare example described in your previous query: estimating the causal effect of hospital quality (\( D_i \), binary: high-quality vs. standard hospital) on patient recovery time (\( Y_i \), continuous: days until recovery) using geographic proximity to a high-quality hospital (\( Z_i \), binary: living within 10 miles vs. not) as the instrument. The code simulates synthetic data, estimates the IV effect using two-stage least squares (2SLS) and the Wald estimator, and visualizes the results. The implementation aligns with the mathematical formalism from your IV query and the context from the healthcare example, ensuring clarity and reproducibility. Comments explain each step, and the code is concise yet comprehensive, incorporating covariates to mirror the example’s realism.

### R Code

```R
# Install and load required packages
if (!requireNamespace("AER", quietly = TRUE)) install.packages("AER")
if (!requireNamespace("ggplot2", quietly = TRUE)) install.packages("ggplot2")
library(AER)
library(ggplot2)

# Set seed for reproducibility
set.seed(123)

# Simulate synthetic data
n <- 1000  # Number of observations
p <- 5     # Number of covariates
X <- matrix(rnorm(n * p), nrow = n)  # Covariates (e.g., age, comorbidities)
colnames(X) <- paste0("X", 1:p)

# Instrument: Z = 1 if within 10 miles of high-quality hospital
Z <- rbinom(n, 1, 0.5)  # Binary instrument, ~50% live near high-quality hospital

# Treatment: D = 1 if treated at high-quality hospital
# First stage: D depends on Z and covariates
pi_1 <- 0.8  # Strong instrument effect
D <- as.numeric(runif(n) < plogis(0.5 + pi_1 * Z + 0.2 * rowSums(X[, 1:2])))

# Outcome: Recovery time (days, lower is better)
true_late <- -5  # True LATE: high-quality hospital reduces recovery by 5 days
Y <- 20 + true_late * D + 2 * rowSums(X[, 1:3]) + rnorm(n, sd = 2)

# Create data frame
data <- data.frame(Y = Y, D = D, Z = Z, X)

# First stage: Check instrument relevance
first_stage <- lm(D ~ Z + ., data = data[, c("D", "Z", paste0("X", 1:p))])
cat("First-stage F-statistic:", summary(first_stage)$fstatistic[1], "\n")

# IV estimation using 2SLS
iv_model <- ivreg(Y ~ D + . | Z + ., data = data[, c("Y", "D", "Z", paste0("X", 1:p))])
iv_results <- summary(iv_model)
cat("2SLS LATE estimate:", coef(iv_results)["D", "Estimate"], "\n")
cat("Standard error:", coef(iv_results)["D", "Std. Error"], "\n")

# Wald estimator for comparison
y_z1 <- mean(data$Y[data$Z == 1])  # Mean outcome when Z = 1
y_z0 <- mean(data$Y[data$Z == 0])  # Mean outcome when Z = 0
d_z1 <- mean(data$D[data$Z == 1])  # Mean treatment when Z = 1
d_z0 <- mean(data$D[data$Z == 0])  # Mean treatment when Z = 0
wald_estimate <- (y_z1 - y_z0) / (d_z1 - d_z0)
cat("Wald estimator LATE:", wald_estimate, "\n")

# Naive OLS for comparison
ols_model <- lm(Y ~ D + ., data = data[, c("Y", "D", paste0("X", 1:p))])
ols_estimate <- coef(ols_model)["D"]
cat("Naive OLS estimate:", ols_estimate, "\n")

# Visualize results
estimates <- data.frame(
  Method = c("2SLS", "Wald", "OLS"),
  Estimate = c(coef(iv_results)["D", "Estimate"], wald_estimate, ols_estimate),
  SE = c(coef(iv_results)["D", "Std. Error"], NA, summary(ols_model)$coefficients["D", "Std. Error"]),
  Lower = c(coef(iv_results)["D", "Estimate"] - 1.96 * coef(iv_results)["D", "Std. Error"], 
            NA, ols_estimate - 1.96 * summary(ols_model)$coefficients["D", "Std. Error"]),
  Upper = c(coef(iv_results)["D", "Estimate"] + 1.96 * coef(iv_results)["D", "Std. Error"], 
            NA, ols_estimate + 1.96 * summary(ols_model)$coefficients["D", "Std. Error"])
)

ggplot(estimates, aes(x = Method, y = Estimate, fill = Method)) +
  geom_bar(stat = "identity", alpha = 0.6) +
  geom_errorbar(aes(ymin = Lower, ymax = Upper), width = 0.2, na.rm = TRUE) +
  geom_hline(yintercept = true_late, linetype = "dashed", color = "red") +
  labs(title = "LATE Estimates: Hospital Quality on Recovery Time", 
       y = "Estimated Effect (Days)", x = "Method") +
  scale_fill_manual(values = c("2SLS" = "#1f77b4", "Wald" = "#ff7f0e", "OLS" = "#2ca02c")) +
  theme_minimal() +
  annotate("text", x = 3.5, y = true_late + 0.5, label = "True LATE", color = "red")
```

### Explanation of Code

The code simulates a dataset with \( n = 1000 \) patients, a binary instrument \( Z_i \) (proximity to a high-quality hospital), a binary treatment \( D_i \) (high-quality vs. standard hospital), and a continuous outcome \( Y_i \) (recovery time in days). Five covariates \( X_i \) (e.g., age, comorbidities) are included to mimic realistic confounding. The true LATE is set to \(-5\), meaning high-quality hospitals reduce recovery time by 5 days for compliers. The instrument is designed to be strong (\( \pi_1 = 0.8 \)), satisfying the relevance assumption (\( \text{Cov}(Z_i, D_i) \neq 0 \)).

The first stage regresses \( D_i \) on \( Z_i \) and covariates to verify relevance, reporting the F-statistic. The IV effect is estimated using 2SLS via the `ivreg` function from the `AER` package, implementing:

\[
D_i = \pi_0 + \pi_1 Z_i + \pi_2 X_i + \nu_i
\]
\[
Y_i = \alpha_0 + \alpha_1 \hat{D}_i + \alpha_2 X_i + \varepsilon_i
\]

The Wald estimator is computed manually as:

\[
\widehat{\text{LATE}} = \frac{\mathbb{E}[Y_i \mid Z_i = 1] - \mathbb{E}[Y_i \mid Z_i = 0]}{\mathbb{E}[D_i \mid Z_i = 1] - \mathbb{E}[D_i \mid Z_i = 0]}
\]

A naive OLS regression is included for comparison, likely biased due to unmeasured confounding (simulated via noise and covariate effects). The results are visualized in a bar chart comparing 2SLS, Wald, and OLS estimates, with error bars for 2SLS and OLS (Wald standard errors are omitted for simplicity).

### Expected Output

- **First Stage**: The F-statistic should exceed 10, confirming relevance.
- **2SLS**: The LATE estimate (\( \alpha_1 \)) should be close to \(-5\), with a standard error and confidence interval.
- **Wald Estimator**: Should approximate the 2SLS estimate, though less precise without covariates.
- **OLS**: Likely biased (e.g., attenuated toward zero) due to confounding.
- **Plot**: A bar chart showing the three estimates, with the true LATE (\(-5\)) as a red dashed line. 2SLS and Wald estimates should be near \(-5\), while OLS may deviate.

### Notes

- **Assumptions**: The simulation assumes exclusion (\( Z_i \) affects \( Y_i \) only through \( D_i \)) and independence (\( Z_i \perp \{Y_i(1), Y_i(0)\} \)) by design. In practice, you’d need to justify these (e.g., proximity doesn’t affect recovery via other channels like local healthcare quality).
- **Extensions**: To explore heterogeneous effects, you could interact \( D_i \) with covariates in the second stage. For robustness, add tests for weak instruments or sensitivity analyses.
- **Packages**: The `AER` package is used for 2SLS; alternatives like `ivpack` offer additional diagnostics.
