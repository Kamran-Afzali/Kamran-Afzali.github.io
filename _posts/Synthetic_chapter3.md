
The utilization of health data for innovation and enhancing care has been a long-standing focus. AI and machine learning (ML) present opportunities to leverage health system data for developing decision support tools, refining treatments, and enhancing system efficiencies. Despite these prospects, significant barriers hinder widespread innovation and adoption. ML applications being data-intensive face challenges related to data access. Privacy concerns act as critical impediments to health data sharing and access. Accessing datasets directly from authors of published studies, an option available, often proves to be poor, with varying and generally low success rates. Challenges are particularly pronounced in European Economic Area (EEA) countries adhering to the stringent EU General Data Protection Regulation (GDPR), which sets high standards for data sharing. The GDPR's global influence further complicates data sharing practices. The concept of a 'privacy chill,' as identified by the Public Health Agency of Canada, underscores the negative impact of restricted health data sharing, affecting pandemic response and the recruitment of skilled health data scientists. Technical solutions, such as synthetic data approaches, emerge as tools to enhance and protect privacy, overcoming the challenges posed by privacy concerns. Synthetic data generation (SDG) involves training ML models on real datasets to capture patterns, enabling the generation of privacy-preserving synthetic data without a direct mapping to the original or real patients.

A symposium organized by CIFAR, IVADO, and Mila in November 2021 delved into the opportunities and challenges of deploying synthetic data approaches in various health applications. The discussions revealed a burgeoning interest in applying synthetic data across health and life sciences. However, realizing its full benefits necessitates further education, research, and policy innovation. 

Machine learning has empowered intelligent computer systems to autonomously tackle tasks, contributing significantly to industrial innovation. Through the integration of high-performance computing, modern modeling, and simulations, machine learning has become an indispensable tool for managing and analyzing massive volumes of data. Despite the current perception of artificial intelligence entering a golden age, challenges persist in its development and application, necessitating solutions for unlocking its full transformative potential across industries.

While machine learning has proven its capability to handle various tasks, it does not consistently provide optimal solutions. Challenges in the field persist, emphasizing the need for continuous efforts to address obstacles hindering the technology's progress. One of the critical challenges lies in data quality, where subpar data can lead to incorrect or imprecise predictions. Additionally, data scarcity poses a significant issue, either due to insufficient available datasets or the excessive cost of manual labeling. The ethical concerns of data privacy and fairness further complicate matters, requiring a balanced and secure approach to the development and deployment of machine learning technologies.

Synthetic data, defined as artificially annotated information generated by computer algorithms or simulations, emerges as a solution to certain challenges in machine learning. This approach becomes particularly relevant when real data is either unavailable or must be kept private due to privacy or compliance risks. The use of synthetic data is pervasive across various sectors, including healthcare, business, manufacturing, and agriculture, with its demand growing exponentially. However, the ethical and secure deployment of synthetic data is crucial to mitigate potential risks associated with privacy and bias, ensuring a responsible and effective integration of this technology in practice.








The utilization of Electronic Health Record (EHR) data, encompassing clinical symptoms, diagnoses, investigations, and treatments, has gained prominence in data mining and machine learning applications. Notable instances include studies by Khalid et al., offering insights into drug use patterns, and Ravizza et al., proposing diagnostic and predictive disease applications. However, a need arises for synthetic datasets to complement real-world data due to challenges such as stringent access regulations, cost inefficiency, and privacy concerns associated with actual patient records.

Accessing individual real-world records, even in pseudonymized form, is subject to strict regulations to prevent inadvertent patient reidentification. Synthetic datasets, devoid of personal identifiers, could streamline data access approvals and accelerate research innovation. The cost-effectiveness of using synthetic data for benchmarking and validation is emphasized, offering a more economical alternative to expanding the coverage of real-world data. Additionally, the efficiency of testing algorithms or functions is highlighted, particularly for scenarios like assessing scalability and robustness.

Patient privacy protection, completeness in data research, and benchmarking capabilities are underscored as advantages of synthetic data. Despite these benefits, there is a lack of a comprehensive synthetic data generation approach for healthcare data that ensures preservation of key characteristics while safeguarding patient privacy. The proposed framework in this article aims to address this gap by focusing on clinically meaningful synthetic data generation while adhering to key requirements such as preserving biological relationships, univariate and multivariate distances, and privacy preservation.


Research in synthetic data generation with a focus on preserving data privacy has garnered attention alongside studies addressing the complexities inherent in healthcare data. This section reviews prior work in these domains to distill lessons applicable to the proposed framework.

Synthetic data generation methods broadly fall into three categories. The first group involves generating synthetic data based on statistical properties of real-world data. This is particularly valuable when real data are challenging to access or exhibit scarcity, as seen in studies sampling data from population distributions or using statistical information and expert knowledge to simulate care patterns. The second group involves adding noise to regenerate part of the real-world data, useful for scenarios such as data imputation to address missing values. The third group utilizes machine learning techniques to generate or extend datasets through prediction and inference, capable of producing both semi-synthetic and fully synthetic data. However, the longitudinal nature and complex format of healthcare data pose additional considerations when employing these approaches.

Privacy preservation, particularly with the introduction of the General Data Protection Regulation (GDPR), is a critical concern. Various approaches, such as perturbation, condensation, randomization, and fuzzy-based methods, have been proposed to mitigate the risk of patient privacy disclosure. Nevertheless, anonymization may compromise data utility, and even anonymized data might carry residual privacy risks, as demonstrated in studies revealing the uniqueness of individuals based on seemingly innocuous information. Fully synthetic datasets offer a potential solution to privacy concerns by ensuring all data values differ from real-world data. However, in clinical studies, relying on a restricted set of values may be necessary to maintain clinical meaningfulness, with the caveat that privacy risks persist if synthetic outliers align with those in real-world data by chance.

The complexity in electronic healthcare data stems from heterogeneous data sources and intricate relationships within the data. Heterogeneity refers to varied data representations, such as cross-sectional versus longitudinal data, with the conversion between these formats posing a processing challenge. Relationships within the data model, involving entities like patient, clinical observation, and drug records, contribute to complexity. Comprehensive data models, as exemplified by multidimensional models, aim to address the intricate relationships, but learning these relationships remains a challenge to retain clinical information fidelity.



**A proposed synthetic data framework** aims to facilitate the synthesis of healthcare data with a focus on maintaining a high degree of similarity to the ground truth, encompassing biological relationships and values, while also safeguarding privacy. The framework delineates several processes, including ground truth selection, synthetic data generation, evaluation, and the iterative selection of sensible synthetic data.

The ground truth selection process involves two intertwined tasks: identifying privacy-sensitive variables and defining biological relationships. The results of these tasks inform the study data model, guiding the choice of a suitable synthetic data generation model. The synthetic data generation process aims to produce synthetic data candidates while ensuring data quality in terms of consistent data values and format. The subsequent evaluation process focuses on assessing key criteria, including biological relationship preservation, univariate and multivariate distances, and privacy preservation. The sensible synthetic data selection is an iterative process that concludes when all evaluation criteria are met.

In the ground truth selection process, variables are chosen based on their relevance to the study context. Privacy-sensitive variable identification involves considering combinations of variables that might pose a risk of reidentification. Reference to guidance from entities like the UK's Information Commissioner's Office (ICO) can aid in predefining a set of sensitive variables. Additionally, well-established biological relationships between variables and the study target must be defined at this stage.

Considerations for the synthetic data generation process include the identification of biological relationships, the privacy-sensitive nature of variables, and the number of variables. Adding noise can be effective when full synthetic data are not needed, but balancing privacy risk with data utility is crucial. Expert-driven approaches and machine learning algorithms offer solutions based on factors such as data accessibility, complexity, and transparency requirements. Transparency becomes vital, especially when interpreting the model architecture and results of machine learning algorithms. A recommendation emphasizes considering more transparent algorithms, such as Bayesian networks, when alternatives are available. After generating synthetic data, a data quality check may be necessary for variables with continuous values to ensure biological plausibility.

The **framework** below outlines key considerations and steps for the generation and evaluation of synthetic data in the context of healthcare. The three highlighted points cover the synthesis process, quality assessment, and privacy assessment, providing a comprehensive approach to ensure the effectiveness, reliability, and privacy preservation of synthetic healthcare data.

**Synthesis Process:**
The synthesis process for generating synthetic data in healthcare begins with the utilization of real-world data. Various techniques can be employed for synthesis, including decision trees, deep learning methods, and iterative proportional fitting. The selection of a specific technique is driven by the nature of the problem at hand and the desired level of data utility. Decision trees may be suitable for certain structured datasets, while deep learning techniques might be more effective in capturing complex patterns. The choice of synthesis method should align with the specific goals of the healthcare application, ensuring that the generated synthetic data retains essential features while mitigating privacy risks.

**Quality Assessment:**
A critical aspect of synthetic data generation in healthcare involves a comprehensive quality assessment. This assessment serves to assure data user that the utility of the synthetic data is acceptable and instills trust in its reliability. Formalizing utility comparisons using similarity metrics enables repeatability and automation in the assessment process. By comparing key characteristics and statistical properties between the original and synthetic datasets, it becomes possible to validate the accuracy of the synthetic data in representing the underlying patterns of the real data. This quality assurance step is pivotal in ensuring that the synthetic data maintains its relevance and reliability for downstream applications, fostering confidence among users and stakeholders.

**Privacy Assessment:**
Privacy assessment is central to evaluate the potential risks associated with synthetic data. It examines the likelihood of individuals being re-identified in the synthetic dataset and assesses the ease with which new information could be inferred if re-identification occurs. Existing frameworks provide empirical methods to quantify privacy risks. Adjustments to synthesis parameters may be necessary to enhance privacy assurances. This iterative approach ensures that the generated synthetic data minimizes the risk of re-identification and unauthorized disclosure, aligning with ethical and legal considerations in healthcare data usage. Regular privacy assessments contribute to the ongoing refinement of synthetic data generation processes, promoting a balance between data utility and individual privacy protection.

**Synthesis Process**
The process of synthetic data generation involves two main categories: Knowledge-Driven Methods and Data-Driven Methods. Knowledge-Driven (KD) approaches, also known as Theory-driven, derive ground truth from publicly available domain-specific knowledge found in academic or research documents, web resources, and human expertise. These methods require manual curation of the generative model, involving rules, statistical, mathematical, or computational models. KD approaches rarely involve real data, making them resilient to disclosure attacks, but their utility depends on the expertise of the model curator. Knowledge-driven methods are especially useful when data access is challenging, allowing for the creation of synthetic data based on statistical metrics extracted from existing literature. However, challenges may arise when dealing with a large number of variables, limiting the ability to capture hidden patterns among them.

On the other hand, Data-Driven Methods derive the generative model directly from actual data, capturing ground realities more rigorously. Machine learning algorithms, commonly used in data-driven approaches, are effective in discovering hidden patterns, making them suitable when stringent requirements on both data utility and privacy exist, especially in scenarios with numerous and complex biological relationships between variables. Despite their advantages, the choice of a machine learning algorithm depends on transparency requirements. While black box models may offer advantages, a more transparent algorithm, such as Bayesian networks, is recommended when interpretability and trust in the underlying logic are crucial. Adding noise can be a pragmatic solution to balance privacy risks and data utility, especially when full synthetic data is not required. However, striking the right balance is essential, as more noise reduces privacy risk but also diminishes data utility, requiring careful consideration of the added noise level and its impact on preserving original correlations between variables.


**Evaluating the quality of synthetic medical**

Evaluating the quality of synthetic medical data is often categorized into three key qualities: fidelity, diversity, and generalization. Fidelity assesses the quality of samples, questioning their distinguishability from real samples and the validity of population inferences made from synthetic ones. Utility, as a narrow evaluation of fidelity that examines validity of inferences. Diversity measures the coverage of the real data population, addressing potential subgroup underrepresentation, while generalization pertains to privacy concerns, examining whether synthetic data samples are replicas of real data.  Various methods are used to evaluate the quality of synthesized data and to ensure its effectiveness in real-world scenarios. One approach involves Human Evaluation, where opinions from domain experts or non-expert users are sought to assess the quality, similarity to real data, and usability in specific applications. For instance, in speech synthesis, evaluators blindly rate synthesized speech against real human speech. However, this method has limitations due to its expense, time-consuming nature, proneness to errors, and lack of scalability, particularly when dealing with high-dimensional data that is challenging for human visualization.

Another strategy is Statistical Difference Evaluation, which entails calculating various statistical metrics on both synthesized and real datasets and comparing the results. Metrics such as medical concept frequency or patient-level clinical features are utilized to gauge the quality of generated electronic health record (EHR) data. Multivariate distance analysis is employed to compare the interrelationship and patterns of data instances in synthetic and ground truth datasets. Various multivariate analysis methods, including nonmetric multidimensional scaling (NMDS), are utilized for this purpose, enabling a comprehensive assessment of the similarities between synthetic and ground truth datasets with smaller differences in statistical properties between synthetic and real data signifying higher quality in synthesized data. Additionally, the Evaluation using a Pre-trained Machine Learning Model is leveraged, especially in generative adversarial networks (GANs), where the discriminator distinguishes between synthesized and real data. The discriminator's output measures how closely synthetic data resembles real data, serving as an indicator of the generator's ability to produce realistic data. This approach extends beyond GANs to other generative models using pre-trained machine learning models for evaluation. Employing a combination of these methods offers researchers and practitioners a well-rounded understanding of the strengths and weaknesses of synthesized data, aiding in continuous improvements in synthetic data generation techniques for practical applications.

There are two stages to the utility assessment. The first stage is general-purpose comparisons of parameters calculated from the real and synthetic data—for example, comparisons of distributions and bivariate correlations. These act as a “smoke test” of the synthesis process. The second stage is more workload-aware utility assessments. Workload-aware utility assessments involve doing analyses on the synthetic data that are similar to the types of analyses that would be performed on the real data if it was available. 


**Implementation and assessment of privacy**

Privacy assessment metrics come in empirical (through privacy attacks) and formal (derived from the generation method) categories. Empirical evaluation takes place post-training using privacy attacks such as data extractions, model inversions, and Membership Inference Attacks (MIA). MIA, commonly employed for assessing privacy in synthetic datasets, predicts whether a data sample was used for training the SDG model. Careful reporting of privacy attack metrics, with emphasis on the true positive rate at low false positive rates, is essential. There is a tradeoff to consider when deciding what information about the SDG generation process should be shared. While releasing a fully trained model aids transparency and reproducibility, it increases privacy risks. Even releasing an untrained model makes synthetic data vulnerable to privacy attacks. The transparency benefit of releasing all components must be weighed against the privacy-transparency trade-off. Finally it is noteworthy that the creation of an ideal private synthetic dataset involves optimizing the privacy-utility trade-off to meet the needs of all stakeholders. This process requires careful evaluation, considering the impact of various privacy attacks, the level of transparency in model sharing, and the trade-off between privacy and utility in data anonymization methods. 
Federated learning (FL) is suggested as a privacy-preserving alternative, creating synthetic data collaboratively while keeping sensitive real data local. However, FL introduces privacy vulnerabilities if not implemented cautiously, emphasizing the importance of a privacy-aware approach. Differential privacy (DP) is recognized as the only privacy protection with a predictable degree of privacy for SDG, although its implementation can be challenging. The privacy-utility trade-off is a crucial consideration in SDG, wherein achieving high-quality synthetic data may come at the cost of reduced privacy. Popular methods like k-anonymization and DP often entail a trade-off between privacy and utility. DP, despite formal privacy guarantees, can lead to high and unpredictable utility reduction. Balancing privacy and utility in SDG is challenging, and promising work aims to address this trade-off rigorously.


## References

- [Generating and evaluating cross-sectional synthetic electronic healthcare data: Preserving data utility and patient privacy](https://onlinelibrary.wiley.com/doi/full/10.1111/coin.12427)
- [Synthetic data as an enabler for machine learning applications in medicine](https://www.sciencedirect.com/science/article/pii/S2589004222016030)
- [Practical Synthetic Data Generation](https://www.oreilly.com/library/view/practical-synthetic-data/9781492072737/)
- [](https://www.zotero.org/groups/5185601/synthetic_data_whitepaper/collections/EARWRPS6/items/YUUMDYNX/collection)
- [Synthetic data generation for tabular health records: A systematic review. Neurocomputing, 493, 28-45. Advance online publication.](https://doi.org/10.1016/j.neucom.2022.04.053)
- [Synthetic data in health care: A narrative review](https://doi.org/10.1371/journal.pdig.0000082)
- [Machine Learning for Synthetic Data Generation](https://arxiv.org/abs/2302.04062) 
- [Synthetic data generation: State of the art in health care domain](https://www.sciencedirect.com/science/article/abs/pii/S1574013723000138)
- [Synthetic data as an enabler for machine learning applications in medicine](https://www.cell.com/iscience/fulltext/S2589-0042(22)01603-0_returnURL=https%3A%2F%2Flinkinghub.elsevier.com%2Fretrieve%2Fpii%2FS2589004222016030%3Fshowall%3Dtrue)


