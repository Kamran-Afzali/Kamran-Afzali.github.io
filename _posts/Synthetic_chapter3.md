
The utilization of health data for innovation and enhancing care has been a long-standing focus. AI and machine learning (ML) present opportunities to leverage health system data for developing decision support tools, refining treatments, and enhancing system efficiencies. Despite these prospects, significant barriers hinder widespread innovation and adoption. ML applications being data-intensive face challenges related to data access. Privacy concerns act as critical impediments to health data sharing and access. Accessing datasets directly from authors of published studies, an option available, often proves to be poor, with varying and generally low success rates. Challenges are particularly pronounced in European Economic Area (EEA) countries adhering to the stringent EU General Data Protection Regulation (GDPR), which sets high standards for data sharing. The GDPR's global influence further complicates data sharing practices. The concept of a 'privacy chill,' as identified by the Public Health Agency of Canada, underscores the negative impact of restricted health data sharing, affecting pandemic response and the recruitment of skilled health data scientists. Technical solutions, such as synthetic data approaches, emerge as tools to enhance and protect privacy, overcoming the challenges posed by privacy concerns. Synthetic data generation (SDG) involves training ML models on real datasets to capture patterns, enabling the generation of privacy-preserving synthetic data without a direct mapping to the original or real patients.

A symposium organized by CIFAR, IVADO, and Mila in November 2021 delved into the opportunities and challenges of deploying synthetic data approaches in various health applications. The discussions revealed a burgeoning interest in applying synthetic data across health and life sciences. However, realizing its full benefits necessitates further education, research, and policy innovation. This article encapsulates insights from the symposium, outlining the opportunities and challenges associated with SDG for health data. Additionally, a case study on synthetic PET scans is presented, offering directions on how this technology can expedite data access for secondary purposes.






Machine learning has empowered intelligent computer systems to autonomously tackle tasks, contributing significantly to industrial innovation. Through the integration of high-performance computing, modern modeling, and simulations, machine learning has become an indispensable tool for managing and analyzing massive volumes of data. Despite the current perception of artificial intelligence entering a golden age, challenges persist in its development and application, necessitating solutions for unlocking its full transformative potential across industries.

While machine learning has proven its capability to handle various tasks, it does not consistently provide optimal solutions. Challenges in the field persist, emphasizing the need for continuous efforts to address obstacles hindering the technology's progress. One of the critical challenges lies in data quality, where subpar data can lead to incorrect or imprecise predictions. Additionally, data scarcity poses a significant issue, either due to insufficient available datasets or the excessive cost of manual labeling. The ethical concerns of data privacy and fairness further complicate matters, requiring a balanced and secure approach to the development and deployment of machine learning technologies.

Synthetic data, defined as artificially annotated information generated by computer algorithms or simulations, emerges as a solution to certain challenges in machine learning. This approach becomes particularly relevant when real data is either unavailable or must be kept private due to privacy or compliance risks. The use of synthetic data is pervasive across various sectors, including healthcare, business, manufacturing, and agriculture, with its demand growing exponentially. However, the ethical and secure deployment of synthetic data is crucial to mitigate potential risks associated with privacy and bias, ensuring a responsible and effective integration of this technology in practice.








The utilization of Electronic Health Record (EHR) data, encompassing clinical symptoms, diagnoses, investigations, and treatments, has gained prominence in data mining and machine learning applications. Notable instances include studies by Khalid et al., offering insights into drug use patterns, and Ravizza et al., proposing diagnostic and predictive disease applications. However, a need arises for synthetic datasets to complement real-world data due to challenges such as stringent access regulations, cost inefficiency, and privacy concerns associated with actual patient records.

Accessing individual real-world records, even in pseudonymized form, is subject to strict regulations to prevent inadvertent patient reidentification. Synthetic datasets, devoid of personal identifiers, could streamline data access approvals and accelerate research innovation. The cost-effectiveness of using synthetic data for benchmarking and validation is emphasized, offering a more economical alternative to expanding the coverage of real-world data. Additionally, the efficiency of testing algorithms or functions is highlighted, particularly for scenarios like assessing scalability and robustness.

Patient privacy protection, completeness in data research, and benchmarking capabilities are underscored as advantages of synthetic data. Despite these benefits, there is a lack of a comprehensive synthetic data generation approach for healthcare data that ensures preservation of key characteristics while safeguarding patient privacy. The proposed framework in this article aims to address this gap by focusing on clinically meaningful synthetic data generation while adhering to key requirements such as preserving biological relationships, univariate and multivariate distances, and privacy preservation.


Research in synthetic data generation with a focus on preserving data privacy has garnered attention alongside studies addressing the complexities inherent in healthcare data. This section reviews prior work in these domains to distill lessons applicable to the proposed framework.

Synthetic data generation methods broadly fall into three categories. The first group involves generating synthetic data based on statistical properties of real-world data. This is particularly valuable when real data are challenging to access or exhibit scarcity, as seen in studies sampling data from population distributions or using statistical information and expert knowledge to simulate care patterns. The second group involves adding noise to regenerate part of the real-world data, useful for scenarios such as data imputation to address missing values. The third group utilizes machine learning techniques to generate or extend datasets through prediction and inference, capable of producing both semi-synthetic and fully synthetic data. However, the longitudinal nature and complex format of healthcare data pose additional considerations when employing these approaches.

Privacy preservation, particularly with the introduction of the General Data Protection Regulation (GDPR), is a critical concern. Various approaches, such as perturbation, condensation, randomization, and fuzzy-based methods, have been proposed to mitigate the risk of patient privacy disclosure. Nevertheless, anonymization may compromise data utility, and even anonymized data might carry residual privacy risks, as demonstrated in studies revealing the uniqueness of individuals based on seemingly innocuous information. Fully synthetic datasets offer a potential solution to privacy concerns by ensuring all data values differ from real-world data. However, in clinical studies, relying on a restricted set of values may be necessary to maintain clinical meaningfulness, with the caveat that privacy risks persist if synthetic outliers align with those in real-world data by chance.

The complexity in electronic healthcare data stems from heterogeneous data sources and intricate relationships within the data. Heterogeneity refers to varied data representations, such as cross-sectional versus longitudinal data, with the conversion between these formats posing a processing challenge. Relationships within the data model, involving entities like patient, clinical observation, and drug records, contribute to complexity. Comprehensive data models, as exemplified by multidimensional models, aim to address the intricate relationships, but learning these relationships remains a challenge to retain clinical information fidelity.



**A proposed synthetic data framework** aims to facilitate the synthesis of healthcare data with a focus on maintaining a high degree of similarity to the ground truth, encompassing biological relationships and values, while also safeguarding privacy. The framework delineates several processes, including ground truth selection, synthetic data generation, evaluation, and the iterative selection of sensible synthetic data.

The ground truth selection process involves two intertwined tasks: identifying privacy-sensitive variables and defining biological relationships. The results of these tasks inform the study data model, guiding the choice of a suitable synthetic data generation model. The synthetic data generation process aims to produce synthetic data candidates while ensuring data quality in terms of consistent data values and format. The subsequent evaluation process focuses on assessing key criteria, including biological relationship preservation, univariate and multivariate distances, and privacy preservation. The sensible synthetic data selection is an iterative process that concludes when all evaluation criteria are met.

In the ground truth selection process, variables are chosen based on their relevance to the study context. Privacy-sensitive variable identification involves considering combinations of variables that might pose a risk of reidentification. Reference to guidance from entities like the UK's Information Commissioner's Office (ICO) can aid in predefining a set of sensitive variables. Additionally, well-established biological relationships between variables and the study target must be defined at this stage.

Considerations for the synthetic data generation process include the identification of biological relationships, the privacy-sensitive nature of variables, and the number of variables. Adding noise can be effective when full synthetic data are not needed, but balancing privacy risk with data utility is crucial. Expert-driven approaches and machine learning algorithms offer solutions based on factors such as data accessibility, complexity, and transparency requirements. Transparency becomes vital, especially when interpreting the model architecture and results of machine learning algorithms. A recommendation emphasizes considering more transparent algorithms, such as Bayesian networks, when alternatives are available. After generating synthetic data, a data quality check may be necessary for variables with continuous values to ensure biological plausibility.






**Evaluating the quality of synthetic medical** data is an active research focus, often categorized into three key qualities: fidelity, diversity, and generalization. Fidelity assesses the quality of samples, questioning their distinguishability from real samples and the validity of population inferences made from synthetic ones. Utility, as a narrow evaluation of fidelity, gauges the validity of inferences, and fidelity metrics can be either computational or involve human evaluation, utilizing distances between real and synthetic data distributions or expert assessments. Diversity measures the coverage of the real data population, addressing potential subgroup underrepresentation, while generalization pertains to privacy concerns, examining whether synthetic data samples are replicas of real data. Privacy assessment metrics come in empirical (through privacy attacks) and formal (derived from the generation method) categories, and stakeholders must determine the balance among these qualities based on their priorities and objectives.


In evaluating the quality of synthesized data, diverse methods are employed to ensure a comprehensive understanding of its effectiveness in real-world scenarios. One approach involves Human Evaluation, where opinions from domain experts or non-expert users are sought to assess the quality, similarity to real data, and usability in specific applications. For instance, in speech synthesis, evaluators blindly rate synthesized speech against real human speech. However, this method has limitations due to its expense, time-consuming nature, proneness to errors, and lack of scalability, particularly when dealing with high-dimensional data that is challenging for human visualization.

Another strategy is Statistical Difference Evaluation, which entails calculating various statistical metrics on both synthesized and real datasets and comparing the results. Metrics such as medical concept frequency or patient-level clinical features are utilized to gauge the quality of generated electronic health record (EHR) data. Smaller differences in statistical properties between synthetic and real data signify higher quality in synthesized data. Additionally, the Evaluation using a Pre-trained Machine Learning Model is leveraged, especially in generative adversarial networks (GANs), where the discriminator distinguishes between synthesized and real data. The discriminator's output measures how closely synthetic data resembles real data, serving as an indicator of the generator's ability to produce realistic data. This approach extends beyond GANs to other generative models using pre-trained machine learning models for evaluation. Employing a combination of these methods offers researchers and practitioners a well-rounded understanding of the strengths and weaknesses of synthesized data, aiding in continuous improvements in synthetic data generation techniques for practical applications.

In the evaluation process, synthetic data generation models produce multiple candidates, necessitating a method to distinguish between them. The evaluation relies on measuring the "distance" to quantify the disparity between the synthetic dataset and the ground truth, denoted as dis(Xs, Xg), where Xs and Xg represent the input spaces of synthetic data and ground truth, respectively. Generally, a smaller distance indicates greater similarity between the two datasets.

Within the univariate distance assessment, discrete variables (D) and continuous variables (C) are considered. For discrete variables, the probability distribution p represents individual variables, while the density function f represents continuous variables. Univariate distance is defined using equations (E1) and (E2), where each variable is independently assessed, and the dis function remains consistent for a variable type. Probability difference and hypothesis test results, such as p-values from tests like the Kolmogorov–Smirnov test (KS test), are utilized as dis functions.

Multivariate distance analysis is employed to compare the interrelationship and patterns of data instances in synthetic and ground truth datasets. The dis function in multivariate distance measures the Euclidean distance in a transformed input space X ∈ ℝk, where the n dimensions can be reduced and projected to shared k dimensions. Various multivariate analysis methods, including nonmetric multidimensional scaling (NMDS), are utilized for this purpose, enabling a comprehensive assessment of the similarities between synthetic and ground truth datasets.


**The implementation and assessment of privacy** in synthetic data generation (SDG) pose challenges and require careful consideration. Privacy of machine learning (ML) products, including SDG, can be empirically evaluated post-training using privacy attacks such as data extractions, model inversions, and Membership Inference Attacks (MIA). MIA, commonly employed for assessing privacy in synthetic datasets, predicts whether a data sample was used for training the SDG model. Careful reporting of privacy attack metrics, with emphasis on the true positive rate at low false positive rates, is essential. The dilemma arises when deciding what information about the SDG generation process should be shared. While releasing a fully trained model aids transparency and reproducibility, it increases privacy risks. Even releasing an untrained model makes synthetic data vulnerable to privacy attacks. The transparency benefit of releasing all components must be weighed against the privacy-transparency trade-off.

Federated learning (FL) is suggested as a privacy-preserving alternative, creating synthetic data collaboratively while keeping sensitive real data local. However, FL introduces privacy vulnerabilities if not implemented cautiously, emphasizing the importance of a privacy-aware approach. Differential privacy (DP) is recognized as the only privacy protection with a predictable degree of privacy for SDG, although its implementation can be challenging. The privacy-utility trade-off is a crucial consideration in SDG, wherein achieving high-quality synthetic data may come at the cost of reduced privacy. Popular methods like k-anonymization and DP often entail a trade-off between privacy and utility. DP, despite formal privacy guarantees, can lead to high and unpredictable utility reduction. Balancing privacy and utility in SDG is challenging, and promising work aims to address this trade-off rigorously.

The creation of an ideal private synthetic dataset involves optimizing the privacy-utility trade-off to meet the needs of all stakeholders. This process requires careful evaluation, considering the impact of various privacy attacks, the level of transparency in model sharing, and the trade-off between privacy and utility in data anonymization methods.
## References

https://onlinelibrary.wiley.com/doi/full/10.1111/coin.12427

https://www.sciencedirect.com/science/article/pii/S2589004222016030

https://www.oreilly.com/library/view/practical-synthetic-data/9781492072737/

https://www.zotero.org/groups/5185601/synthetic_data_whitepaper/collections/EARWRPS6/items/YUUMDYNX/collection

https://arxiv.org/abs/2302.04062


