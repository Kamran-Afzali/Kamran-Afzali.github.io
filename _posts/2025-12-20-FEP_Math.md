---
layout: post
categories: posts
title: Mathematical Formalism of FEP and Active Inference
featured-image: /images/NIb.jpg
tags: [Free Energy Principle, Predictive Processing, Active Inference]
date-string: December 2025
---
# Mathematical Formalism of FEP and Active Inference

The Free Energy Principle (FEP) and its algorithmic implementation in Active Inference represent a unifying theory of cognition, perception, and action. Rooted in statistical physics and variational Bayesian inference, this framework posits that biological systems maintain their structural and functional integrity by minimizing a variational upper bound on sensory surprise (negative log model evidence). This minimization drives both perceptual inference and decision-making, allowing organisms to navigate uncertainty while maintaining homeostasis.

Although widely cited in cognitive science, neuroscience, and machine learning, the underlying mathematics of FEP and Active Inference can seem opaque. This post provides a rigorous walkthrough of its formal architecture, transitioning from basic probability and variational principles to advanced formulations involving path integrals, gradient flows, and stochastic differential equations. The aim is to show that, far from being metaphysical or speculative, the FEP is grounded in well-established principles of information theory, thermodynamics, and statistical inference.

## Generative Models and Bayesian Inference

At the heart of the FEP is a **generative** model, which encodes how an agent believes sensory data arise from hidden states of the world. Let $s$ denote hidden states and $o$ denote sensory observations. The generative model defines the joint distribution:

$$
P(o, s)
$$

This joint distribution specifies the agent's beliefs about how sensory inputs $o$ are generated from latent causes $s$. From this, inference becomes the process of computing the posterior:

$$
P(s \mid o) = \frac{P(o, s)}{P(o)}
$$

Exact computation is often intractable because it requires evaluating the model evidence $P(o) = \sum_s P(o, s)$ (or an integral in continuous domains). Active Inference therefore employs variational inference, approximating the true posterior with a tractable distribution $Q(s)$ drawn from a restricted family.

## Variational Free Energy

The quality of this approximation is measured by the variational free energy $F$, defined as:

$$
F = \mathbb{E}_{Q(s)}[\log Q(s) - \log P(o, s)]
$$

This is (up to sign) the Evidence Lower Bound (ELBO) familiar from variational inference, and it satisfies:

$$
F = D_{\text{KL}}(Q(s) \| P(s \mid o)) - \log P(o)
$$

Here, $D_{\text{KL}}$ is the Kullback–Leibler divergence. Because $-\log P(o)$ is constant with respect to $Q$, minimizing $F$ is equivalent to minimizing the divergence between the approximate and true posteriors. Thus, perception can be written as:

$$
Q^*(s) = \arg\min_Q F
$$

In this formalism, the agent infers the most plausible hidden causes of its observations by minimizing free energy.

## Action and Expected Free Energy

While perception corresponds to belief updating about the present, action requires planning over possible futures. To model this, Active Inference introduces the **expected free energy** $G(\pi)$, which evaluates a policy $\pi$ — a (possibly stochastic) sequence of future actions — based on its expected impact on beliefs and sensory states:

$$
G(\pi) = \mathbb{E}_{Q(o, s \mid \pi)}[\log Q(s \mid \pi) - \log P(o, s)]
$$

Under standard factorizations of the generative model and recognition density, this expression can be decomposed as:

$$
G(\pi) = \mathbb{E}_{Q(o \mid \pi)}\left[ D_{\text{KL}}(Q(s \mid o, \pi) \| P(s)) \right] - \mathbb{E}_{Q(o \mid \pi)}[\log P(o)]
$$

This decomposition reveals two fundamental components:

1. **Epistemic value** (information gain): the expected divergence between posterior and prior beliefs, encouraging policies that resolve uncertainty.
2. **Extrinsic value** (preference fulfilment): the expected log probability of outcomes under prior preferences, guiding goal-directed behavior.

By selecting the policy that minimizes $G(\pi)$, the agent balances exploration and exploitation:

$$
\pi^* = \arg\min_\pi G(\pi)
$$

This converts action selection into variational inference over policies.

## Generalized Free Energy in Continuous Time

In continuous-time formulations, beliefs and observations evolve along trajectories. This is captured by a generalized free energy functional:

$$
\mathcal{F}[q] = \int_0^T \mathbb{E}_{q(s_t)}\left[ \log q(s_t) - \log p(o_t, s_t) \right] \, dt
$$

Here, $q(s_t)$ is the time-indexed approximate posterior, and $p(o_t, s_t)$ is the generative model at time $t$. This integral defines a path-dependent cost functional, analogous to action functionals in Lagrangian mechanics.

Minimizing this functional yields variational dynamics of the form:

$$
\frac{dq(s_t)}{dt} = - \nabla_q \mathcal{F}[q]
$$

This defines a gradient flow on the space of probability densities, closely related to Fokker–Planck or continuity equations that govern the time evolution of distributions in stochastic systems.

## Generalized Coordinates of Motion

To model perception in continuous environments, the FEP makes use of **generalized coordinates of motion**:

$$
\tilde{s} = \{s, \dot{s}, \ddot{s}, \dots\}
$$

These extended state representations encode position, velocity, acceleration, and higher-order temporal derivatives of hidden states. By representing sensory flows over time, the generative model can predict smooth temporal trajectories instead of isolated snapshots.

This is essential for capturing the temporal structure of perception, particularly in vision and proprioception, where higher-order dynamics (e.g., motion and acceleration) carry information that is critical for accurate interpretation and control.

## Decomposition of Expected Free Energy

Returning to the discrete-time expected free energy, its decomposition highlights how Active Inference simultaneously reduces uncertainty and pursues preferred states. The formal expression:

$$
G(\pi) = \mathbb{E}_{q(o \mid \pi)}\left[ D_{\text{KL}}(q(s \mid o, \pi) \| p(s)) \right] - \mathbb{E}_{q(o \mid \pi)}[\log p(o)]
$$

splits into:

- The first term, epistemic value, quantifies expected information gain by measuring the divergence between posterior and prior beliefs. It favors policies that generate informative observations.
- The second term, extrinsic value, quantifies the expected log probability of outcomes under prior preferences. It favors policies that steer the agent toward preferred or biologically viable states.

Crucially, both terms are consequences of a single generative model and require no separate reward function, which distinguishes Active Inference from many reinforcement learning formulations based on externally specified utilities.

## Active Inference as Stochastic Optimal Control

The FEP also admits an interpretation within stochastic control theory. Let the system dynamics be given by:

$$
ds_t = f(s_t, a_t)\,dt + \omega_t, \quad o_t = g(s_t) + \nu_t
$$

with $\omega_t$ and $\nu_t$ representing process and observation noise, respectively. In place of minimizing an explicit cost function $C(s, a)$, the agent minimizes expected free energy over policies:

$$
\pi^* = \arg\min_\pi \mathbb{E}_{q(o, s \mid \pi)}[\mathcal{F}]
$$

Under appropriate choices of generative model and preferences, this framing yields a form of risk-sensitive, information-seeking control. It embeds traditional control objectives (e.g., target reaching or set-point regulation) within a broader variational architecture that also encodes uncertainty reduction and predictive consistency.

## Information-Theoretic Foundations

At a deeper level, the FEP is an information-theoretic principle. It states that agents minimize the divergence between predicted and actual sensory states, thereby maximizing the mutual information between internal beliefs and observations, subject to model constraints.

In this setting, expected free energy bounds the expected surprise of observations under a given policy:

$$
G(\pi) \geq -\log P(o \mid \pi)
$$

Minimizing $G(\pi)$ therefore leads agents to select actions that render future observations less surprising and more consistent with their prior preferences and generative model. This information-theoretic view aligns with efficient coding hypotheses in neuroscience and with Shannon’s treatment of entropy and uncertainty.

## Thermodynamic Analogy

A compelling interpretation of the FEP is thermodynamic. Variational free energy can be written in a form that mirrors the Helmholtz free energy from statistical physics:

$$
F = U - T S
$$

Here, $U$ denotes an expected energy or internal energy term (often related to expected negative log likelihood), $S$ is an entropy term, and $T$ plays a role analogous to an effective temperature or precision. In the FEP context, internal energy reflects the agent’s confidence in its generative model, whereas entropy captures uncertainty about hidden causes.

By minimizing variational free energy, the agent counteracts entropy-increasing environmental perturbations and preserves its characteristic states. This explains why biological systems can persist and adapt despite ongoing exposure to stochastic sensory inputs: life can be viewed as the continual suppression of surprise, or more formally, as the sustained minimization of variational free energy over time.

### Table: Summary of Key Mathematical Constructs in FEP and Active Inference

| **Concept** | **Mathematical Expression** | **Interpretation** |
| :-- | :-- | :-- |
| **Generative model** | $P(o, s)$ | Joint probability over observations $o$ and hidden states $s$ |
| **Bayesian inference** | $P(s \mid o) = \frac{P(o, s)}{P(o)}$ | Posterior belief about hidden causes given observations |
| **Variational free energy** | $F = \mathbb{E}_{Q(s)}[\log Q(s) - \log P(o, s)]$ | Upper bound on surprise; minimized in perceptual inference |
| **Free energy decomposition** | $F = D_{\text{KL}}(Q(s) \| P(s \mid o)) - \log P(o)$ | Complexity–accuracy trade-off in approximate inference |
| **Perceptual inference** | $Q^*(s) = \arg\min_Q F$ | Optimal approximate posterior under free energy minimization |
| **Expected free energy** | $G(\pi) = \mathbb{E}_{Q(o, s \mid \pi)}[\log Q(s \mid \pi) - \log P(o, s)]$ | Evaluates policies in terms of predicted beliefs and outcomes |
| **EFE decomposition** | $G(\pi) = \mathbb{E}_{Q(o)}[D_{\text{KL}}(Q(s \mid o) \| P(s))] - \mathbb{E}_{Q(o)}[\log P(o)]$ | Epistemic (information gain) plus extrinsic (preference) value |
| **Policy selection** | $\pi^* = \arg\min_\pi G(\pi)$ | Select policies that minimize expected free energy |
| **Path integral formulation** | $\mathcal{F}[q] = \int_0^T \mathbb{E}_{q(s_t)}[\log q(s_t) - \log p(o_t, s_t)] \, dt$ | Generalized free energy over time in continuous systems |
| **Gradient flow on beliefs** | $\frac{dq(s_t)}{dt} = - \nabla_q \mathcal{F}[q]$ | Belief dynamics follow variational gradient descent |
| **Generalized coordinates** | $\tilde{s} = \{s, \dot{s}, \ddot{s}, \dots\}$ | Temporally extended representation of hidden states |
| **Thermodynamic analogy** | $F = U - T S$ | Internal energy minus entropy (information-theoretic analogue) |
| **Information-theoretic bound** | $G(\pi) \geq -\log P(o \mid \pi)$ | Expected free energy upper-bounds expected surprise |

## Conclusion

The Free Energy Principle and Active Inference framework provide a mathematically coherent and unifying theory of adaptive behavior. This framework is grounded in variational Bayesian inference, stochastic control, information geometry, and nonequilibrium thermodynamics, rather than in metaphysical assumptions.

Through the minimization of variational free energy, agents simultaneously infer the hidden causes of their sensations and select actions that balance uncertainty reduction with goal-directed behavior. This dual role of inference — retrospective (perception) and prospective (action) — is rendered tractable through variational methods, expected free energy, and gradient flows on belief manifolds.

From the derivation of the expected free energy functional to its decomposition into epistemic and extrinsic value, the FEP offers not just a metaphor but a precise algorithmic account of perception and action. As computational implementations mature, FEP and Active Inference are poised to reshape the understanding of adaptive systems — from brains and bodies to robots and synthetic agents — all governed by the same imperative: to minimize the surprise of existence.
