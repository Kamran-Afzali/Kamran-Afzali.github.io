
The rise of digital health technologies has led to the generation of both qualitative and quantitative "big data" including digital traces of our everyday behaviors. This data holds valuable information that could potentially benefit patients and caregivers. However, the rapid integration of digital health technologies and artificial intelligence (AI) into research and clinical practice raises significant ethical concerns that need to be addressed.

Literature in ethics of AI in health suggests that the governance of digital health research is currently a "wild west" with various stakeholders involved, including technology developers, funders, researchers, participants, and journal editors. The regulatory controls and standards are not currently on par to guide this convergence in the health ecosystem. Several gaps and opportunities exist in the digital health research landscape. Firstly, there are disciplinary and sector challenges, as technology makers may not understand patients' needs, computational scientists may train AI on unrepresentative datasets, and clinicians may struggle to make sense of AI-driven decisions. Secondly, there is a need to improve digital and technology literacy among various stakeholders, including policymakers, educators, regulators, clinicians, patients, and caregivers. Thirdly, there is a lack of consistent ethical and regulatory standards for evaluating and testing new digital health technologies and AI systems. Regulatory bodies and technologists may lack the necessary expertise or training to conduct appropriate risk assessments and ensure ethical practices. 

To address these gaps, several initiatives have emerged to examine the [ethical, legal, and social implications (ELSI) of digital health and AI technologies](https://journals.plos.org/digitalhealth/article?id=10.1371/journal.pdig.0000607). Groups like the [Connected and Open Research Ethics (CORE)](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5322198/)initiative, [Pervasive Data Ethics for Computational Research (PERVADE)](https://pervade.umd.edu/), and [Mobile Health ELSI (mHealthELSI)](https://elsihub.org/grant-abstract/addressing-elsi-issues-unregulated-health-research-using-mobile-devices) project aim to inform policy and governance in this largely unregulated space. However, many of these efforts are broad in scope and may lack specificity for digital health applications. While regulations are slowly emerging, stakeholders must recognize their ethical obligation to uphold the integrity of digital health research in this unregulated space. To address these challenges, literature points towards a digital health decision-making framework with five main domains: **Participant Privacy, Risks and Benefits, Access and Usability, Data Management, and Ethical Principles**. Along theses lines, implementing digital health tools requires careful consideration of ethical principles, risk/benefit assessments, privacy protection, equitable access and usability, and sound data management practices. Collective action is needed to establish ethical standards and accountability measures to ensure the responsible development and use of digital health technologies. This document is a first effort to get an outlook of ethical considerations in digital health and precision medicine research projects. The Research Ethics Committees (RECs) emphasize the importance of inclusivity and equity in digital health studies, below we number some of the points that could be brought up RECs.

### Considerations


**Equity** 

- Equity is defined by equal access to digital technology and healthcare, equity in treatment, non-discrimination, data ownership, and empowerment. Here the aim is to ensure that precision medicine and digital health solutions are accessible to all populations, including underprivileged and minority groups.

**Participant Safety and Support**

- A significant portion of discussions revolves around public and patient involvement (PPI) in study design and the development of comprehensible materials. This involvement helps address concerns about participant burden and frustration with the technology. Amendments to recruitment protocols are often requested to reduce participant pressure and ensure voluntary participation. Safety measures for control groups and sensitive populations, with well-considered arrangements, are required. Clear and user-friendly instructions for technology usage are essential, and studies involving high-risk devices must undergo safety checks before approval.


**Conflict of Interest**

- Applicants must disclose all affiliations with sponsors and ensure that financially affiliated researchers do not consent patients. RECs place emphasis on clarifying relationships between researchers, organizations, and study locations, especially when submitted to Higher Education Institution RECs.

**Cost-benefit**

- The cost-benefit ratio of digital health solutions is another important issue, as some professionals argue that other health interventions might offer greater benefits and deserve better funding. Reallocating resources towards improving living conditions and health-related behaviors, could potentially yield more significant health benefits. Despite these concerns, some studies indicate that the digital health solution is at least as cost-effective as conventional care, warranting further investigation into its economic viability.

**Harm Prevention**

- Harm prevention is critical, with most applications encountering barriers related to unforeseen events such as participant non-adherence or emergencies. Mechanisms must be in place to detect and address these issues with a consideration for high-risk patients. Clear reaction protocols for unexpected events, such as device failures, are essential. Proper training for staff and clinicians, sterilization of materials, and listing device contraindications are emphasized to avert potential risks.

**Data Governance**

- Data management, including storage, access, and transfer, is a significant focus. Applicants must de-identify data, clarify device ownership, and justify their storage/compute methods. Clear procedures for handling data upon participant withdrawal are required, along with secure data transfer protocols, especially in international collaborations. Anonymization and confidentiality strategies must be detailed, distinguishing between pseudonymous and anonymous data. Video and audio recording justifications are necessary, particularly regarding the duration of storage and sharing with sponsors.

**Fairness of AI and algorithms**

- Concerns about the fairness of AI and algorithms in digital health primarily revolve around bias, uncertainty, and transparency. AI systems can inherit biases from the data they are trained on, potentially leading to unequal treatment of different patient groups. This bias can exacerbate existing health disparities, particularly affecting marginalized communities. Along the same lines, transparency in how algorithms make decisions is crucial, yet many AI models are "black boxes," making it difficult for healthcare providers and patients to understand and trust their outputs. 

### conclusion

The integration of digital health technologies and AI into clinical practice and research presents both opportunities, as these technologies can transform healthcare by providing valuable insights and improving patient outcomes through data-driven decision-making. However, the ethical concerns surrounding privacy, equity, fairness, and safety remain to be addressed and the governance of digital health remains underdeveloped, leading to inconsistent standards across stakeholders like researchers, clinicians, and technologists. Current efforts, such as frameworks focusing on participant privacy, access, data management, and ethical principles, are essential first steps but require further refinement to ensure the responsible use of digital health technologies. Addressing these challenges is complex, with major obstacles such as the lack of standardization in regulatory and ethical frameworks that requires bridging the knowledge/framework gaps among technology developers, healthcare providers, and regulatory bodies to ensure that AI models are trained on representative datasets and that their outputs are interpretable. Another challenge lies in enhancing digital literacy across all stakeholders, including patients, clinicians, and policymakers, to ensure informed participation and decision-making in this rapidly evolving field. Moreover, balancing cost-benefit considerations with equitable access to these technologies remains a pressing issue, especially for underserved populations.

Future research should focus on developing robust frameworks for ethical AI deployment in healthcare, ensuring fairness in algorithmic design, and addressing the biases embedded within these systems. Investigating the long-term societal impacts of digital health technologies on health equity, as well as improving transparency in AI-driven decision-making, are also important areas for future study. Furthermore, exploring international collaborations and their implications for data governance could provide valuable insights into creating more inclusive and secure digital health ecosystems. Establishing clearer ethical and regulatory guidelines will be vital to harnessing the full potential of digital health while safeguarding patient rights and well-being.

### Questions

**Privacy and Confidentiality**

-   How will patient data be protected from unauthorized access and breaches?
-   What measures are in place to ensure data confidentiality?

**Informed Consent**

-   How will informed consent be obtained and documented?
-   Are patients provided with comprehensive information about the potential risks and benefits of the study?

**Data Governance**

-   What are the policies for data storage, sharing, and usage?
-   How will data be anonymized or de-identified to protect patient privacy?

**Equity and Access**

-   How will the project ensure equitable access to precision medicine and digital health solutions?
-   Are there strategies to include underprivileged and minority groups in the study?

**Psychosocial Impact**

-   What are the potential psychological and social effects on patients?
-   How will the project address and mitigate potential negative effects?

**Discrimination and Stigmatization**

-   What safeguards are in place to prevent the misuse information by employers, insurers, or other entities?
-   How will the project address concerns about potential discrimination and stigmatization?

**Doctor-Patient Relationship**

-   How will the project maintain the quality of the doctor-patient relationship?
-   What steps are taken to ensure that the focus on data does not undermine patient care?

**Cost and Economic Impact**

-   What is the financial burden on patients participating in the study?
-   How will the project ensure cost-effectiveness and avoid unnecessary expenses?

**Autonomy and Decision-Making**

-   How will the project respect patients' autonomy and their right to make informed decisions?
-   Are there mechanisms to support patients in understanding their options and making informed choices?

**Fairness of AI and Algorithms**

-   What measures are in place to ensure transparency, fairness, and accountability in the use of AI?



### References:

- [Patients' perspectives related to ethical issues and risks in precision medicine: a systematic review](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC10310545/)
- [Patients' and professionals' views related to ethical issues in precision medicine: a mixed research synthesis](https://bmcmedethics.biomedcentral.com/articles/10.1186/s12910-021-00682-8)
- [Practical Challenges for Commercial Enterprises in the Ethics Review Process for Digital Health Research: Document Analysis and Interview Study](https://www.medrxiv.org/content/10.1101/2024.01.28.24301885v1.full)
- [The ethical challenges facing the widespread adoption of digital healthcare technology](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7612237)
- [Building the case for actionable ethics in digital health research supported by artificial intelligence](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6636063/)
- [Ethical Issues in Precision Medicine](https://bioethics.pitt.edu/sites/default/files/MesserSlides/2020/LSParker%20-%20Ethical%20Issues%20in%20Precision%20Medicine%20-%202020.pdf)
- [Ethical issues in biomedical research using electronic health records: a systematic review](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8214390)
- [Using digital health to enable ethical health research in conflict and other humanitarian settings](https://conflictandhealth.biomedcentral.com/articles/10.1186/s13031-018-0163-z)
- [Emerging ethical issues regarding digital health data. On the World Medical Association Draft Declaration on Ethical Considerations Regarding Health Databases and Biobanks](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4856186)


La croissance des technologies de santé numérique a amené la génération de "big data" qualitatives et quantitatives, y compris les traces numériques de nos comportements quotidiens. Ces données contiennent des informations qui pourraient bénéficier aux patients et aux soignants. Cependant, l'intégration rapide des technologies de santé numérique et de l'intelligence artificielle (IA) dans la recherche et la pratique clinique soulève d'importantes préoccupations éthiques qui doivent être abordées.

La littérature suggère que la gouvernance de la recherche numérique en matière de santé est actuellement un "Far West" avec diverses parties prenantes impliquées, y compris les développeurs de technologies, les organisations subventionairs, les chercheurs, les participants/patients. Les contrôles et les normes réglementaires ne sont actuellement pas à la hauteur pour guider cette convergence dans l'écosystème de la santé. Le paysage de la recherche en santé numérique présente plusieurs lacunes et opportunités. Tout d'abord, il existe des défis disciplinaires, car les concepteurs des technologies peuvent ne pas comprendre les besoins des patients, les informaticiens peuvent entrainer l'IA sur des ensembles de données non représentatifs, et les cliniciens peuvent avoir du mal à donner un sens aux décisions prises par l'IA. Deuxièmement, il est nécessaire d'améliorer la culture numérique et technologique des différentes parties prenantes, notamment les décideurs politiques, les éducateurs, les régulateurs, les cliniciens, les patients et les soignants. Troisièmement, il n'existe pas de normes éthiques et réglementaires cohérentes pour évaluer et tester les nouvelles technologies de santé numérique et les systèmes d'IA. Les organismes de réglementation et les technologues peuvent ne pas disposer de l'expertise ou de la formation nécessaire pour procéder à des évaluations des risques appropriées et garantir des pratiques éthiques.

Pour combler ces lacunes, plusieurs initiatives existent afin d'examiner les implications éthiques, juridiques et sociales (ELSI) de la santé numérique et des technologies de l'IA. Des groupes tels que l'initiative Connected and Open Research Ethics (CORE), Pervasive Data Ethics for Computational Research (PERVADE) et le projet Mobile Health ELSI (mHealthELSI) visent à informer les politiques et la gouvernance dans cet espace largement non réglementé. Toutefois, ces efforts ont une portée générale et peuvent manquer de spécificité pour les applications de santé numérique. Alors que les réglementations émergent lentement, les parties prenantes doivent reconnaître leur obligation éthique de maintenir l'intégrité de la recherche en santé numérique dans cet espace non réglementé. Pour relever ces défis, la littérature s'oriente vers un cadre décisionnel en matière de santé numérique comprenant cinq domaines principaux : Vie privée des participants, Risques et avantages, Accès et facilité d'utilisation, Gestion des données et Principes éthiques. Dans cette optique, la mise en œuvre des outils et techniques de santé numérique nécessite un examen attentif des principes éthiques, de l'évaluation des risques et des avantages, de la protection de la vie privée, de l'accès équitable et de la facilité d'utilisation, ainsi que des pratiques saines de gestion des données. Une action collective est nécessaire pour établir des normes éthiques et des mesures de responsabilisation afin de garantir le développement et l'utilisation responsables des technologies numériques de santé. Ce document est un premier effort pour obtenir un aperçu des considérations éthiques dans les projets de recherche en santé numérique et en médecine de précision.

Les comités d'éthique de la recherche (CER) soulignent l'importance de l'inclusivité et de l'équité dans les études sur la santé numérique, nous énumérons ci-dessous certains des points qui pourraient être soulevés par les CER.

### Considérations


**L'équité** 

- L'équité est définie par l'égalité d'accès à la technologie numérique et aux soins de santé, l'égalité de traitement, la non-discrimination, la propriété des données et l'autonomisation. Il s'agit ici de s'assurer que la médecine de précision et les solutions de santé numérique sont accessibles à toutes les populations, y compris les groupes défavorisés et minoritaires.

**Sécurité et soutien des participants**

- La participation du public et des patients (PPI) à la conception de l'étude et à l'élaboration de documents compréhensibles est un autre aspect important. Cette participation permet d'atténuer les fardeaux potentiels sur les participants et leur frustration face à la technologie. Des modifications des protocoles de recrutement sont souvent demandées pour réduire tout type de stress sur les participants et garantir leur participation volontaire. Les mesures de sécurité pour les groupes de contrôle et les populations sensibles font l'objet d'un examen critique. Des instructions claires pour l'utilisation de la technologie sont essentielles, et les études impliquant des dispositifs à haut risque doivent faire l'objet de contrôles de sécurité avant d'être approuvées.

**Conflit d'intérêts**

- Les candidats doivent divulguer toutes les affiliations avec des sponsors et s'assurer que les chercheurs affiliés financièrement ne consentent pas à des patients. Les CER mettent l'accent sur la clarification des relations entre les chercheurs, les organisations et les lieux d'étude, en particulier lorsqu'ils sont soumis aux CER des établissements d'enseignement supérieur.

**Coût-bénéfice**

- La réaffectation des ressources à l'amélioration des conditions de vie et des comportements liés à la santé pourrait avoir des effets bénéfiques plus importants sur la santé. Ainsi, le rapport coût-bénéfice des solutions de santé numérique est une autre question controversée.  Certaines études indiquent que les solutions de santé numérique sont moins rentable que les soins conventionnels, ce qui justifie un examen plus approfondi de leurs viabilité économique.

**Prévention des risques/dommages**

- Des mécanismes doivent être mis en place pour détecter et traiter rapidement des pontentiels risques/dommages. Des protocoles de réaction clairs en cas d'événements inattendus, tels que des défaillances d'appareils ou fausses prédictions d'un modèle d'IA, sont essentiels. Une formation adéquate du personnel et des cliniciens et l'établissement d'une liste des contre-indications des dispositifs, outils, ou models sont des éléments essentiels pour prévenir les risques potentiels.
  
### Questions

**Protection de la vie privée et de la confidentialité**

- Comment les données des patients seront-elles protégées?
- Quelles sont les mesures mises en place pour garantir la confidentialité des données ?

**Consentement éclairé**

- Comment le consentement éclairé sera-t-il obtenu et documenté ?
- Les patients reçoivent-ils des informations complètes sur les risques et les bénéfices potentiels de l'étude ?

**Gouvernance des données**

- Quelles sont les politiques en matière de stockage, de partage et d'utilisation secondaire des données ?
- Comment les données seront-elles anonymisées ou dépersonnalisées pour protéger la vie privée des patients ?

**Équité et accès**

- Comment le projet garantira-t-il un accès équitable à la médecine de précision et aux solutions de santé numérique ?
- Existe-t-il des stratégies pour inclure les groupes défavorisés et minoritaires dans l'étude ?

**Impact psychosocial**

- Quels sont les effets psychologiques et sociaux potentiels sur les patients ?
- Comment le projet abordera-t-il et atténuera-t-il les effets négatifs potentiels ?

**Discrimination et stigmatisation**

- Comment le projet répondra-t-il aux préoccupations concernant les bias, la discrimination et la stigmatisation potentielles ?

**Relation médecin-patient**

- Comment le projet affecte la qualité de la relation médecin-patient ?
- Quelles sont les mesures prises pour garantir que l'accent mis sur les données ne porte pas atteinte à la qualité des soins?

**Autonomie et prise de décision**

- Comment le projet respectera-t-il l'autonomie des patients et leur droit à prendre des décisions en connaissance de cause ?
- Existe-t-il des mécanismes pour aider les patients à comprendre les options qui s'offrent à eux et à faire des choix éclairés ?

**Équité de l'IA et des algorithmes**

- Quelles sont les mesures mises en place pour garantir la transparence, l'équité et la responsabilité dans l'utilisation de l'IA ?

